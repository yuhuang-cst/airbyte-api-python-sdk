"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

# from __future__ import annotations
import dataclasses
from ..shared import airbytecatalog as shared_airbytecatalog
from ..shared import catalogdiff as shared_catalogdiff
from ..shared import connectionschedule as shared_connectionschedule
from ..shared import connectionscheduledata as shared_connectionscheduledata
from ..shared import connectionscheduletype_enum as shared_connectionscheduletype_enum
from ..shared import connectionstatus_enum as shared_connectionstatus_enum
from ..shared import destinationread as shared_destinationread
from ..shared import geography_enum as shared_geography_enum
from ..shared import jobstatus_enum as shared_jobstatus_enum
from ..shared import namespacedefinitiontype_enum as shared_namespacedefinitiontype_enum
from ..shared import nonbreakingchangespreference_enum as shared_nonbreakingchangespreference_enum
from ..shared import operationread as shared_operationread
from ..shared import resourcerequirements as shared_resourcerequirements
from ..shared import schemachange_enum as shared_schemachange_enum
from ..shared import sourceread as shared_sourceread
from airbyte import utils
from dataclasses_json import Undefined, dataclass_json
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class WebBackendConnectionRead:
    r"""Successful operation"""
    
    connection_id: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('connectionId') }})
    destination: shared_destinationread.DestinationRead = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('destination') }})
    destination_id: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('destinationId') }})
    is_syncing: bool = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('isSyncing') }})
    name: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('name') }})
    non_breaking_changes_preference: shared_nonbreakingchangespreference_enum.NonBreakingChangesPreferenceEnum = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('nonBreakingChangesPreference') }})
    notify_schema_changes: bool = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('notifySchemaChanges') }})
    schema_change: shared_schemachange_enum.SchemaChangeEnum = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('schemaChange') }})
    source: shared_sourceread.SourceRead = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('source') }})
    source_id: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sourceId') }})
    status: shared_connectionstatus_enum.ConnectionStatusEnum = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('status') }})
    r"""Active means that data is flowing through the connection. Inactive means it is not. Deprecated means the connection is off and cannot be re-activated. the schema field describes the elements of the schema that will be synced."""
    sync_catalog: shared_airbytecatalog.AirbyteCatalog = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('syncCatalog') }})
    r"""describes the available schema (catalog)."""
    catalog_diff: Optional[shared_catalogdiff.CatalogDiff] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('catalogDiff'), 'exclude': lambda f: f is None }})
    r"""Describes the difference between two Airbyte catalogs."""
    catalog_id: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('catalogId'), 'exclude': lambda f: f is None }})
    geography: Optional[shared_geography_enum.GeographyEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('geography'), 'exclude': lambda f: f is None }})
    latest_sync_job_created_at: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('latestSyncJobCreatedAt'), 'exclude': lambda f: f is None }})
    r"""epoch time of the latest sync job. null if no sync job has taken place."""
    latest_sync_job_status: Optional[shared_jobstatus_enum.JobStatusEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('latestSyncJobStatus'), 'exclude': lambda f: f is None }})
    namespace_definition: Optional[shared_namespacedefinitiontype_enum.NamespaceDefinitionTypeEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('namespaceDefinition'), 'exclude': lambda f: f is None }})
    r"""Method used for computing final namespace in destination"""
    namespace_format: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('namespaceFormat'), 'exclude': lambda f: f is None }})
    r"""Used when namespaceDefinition is 'customformat'. If blank then behaves like namespaceDefinition = 'destination'. If \\"${SOURCE_NAMESPACE}\\" then behaves like namespaceDefinition = 'source'."""
    operation_ids: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('operationIds'), 'exclude': lambda f: f is None }})
    operations: Optional[list[shared_operationread.OperationRead]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('operations'), 'exclude': lambda f: f is None }})
    prefix: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('prefix'), 'exclude': lambda f: f is None }})
    r"""Prefix that will be prepended to the name of each stream when it is written to the destination."""
    resource_requirements: Optional[shared_resourcerequirements.ResourceRequirements] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('resourceRequirements'), 'exclude': lambda f: f is None }})
    r"""optional resource requirements to run workers (blank for unbounded allocations)"""
    schedule: Optional[shared_connectionschedule.ConnectionSchedule] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('schedule'), 'exclude': lambda f: f is None }})
    r"""if null, then no schedule is set."""
    schedule_data: Optional[shared_connectionscheduledata.ConnectionScheduleData] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('scheduleData'), 'exclude': lambda f: f is None }})
    r"""schedule for when the the connection should run, per the schedule type"""
    schedule_type: Optional[shared_connectionscheduletype_enum.ConnectionScheduleTypeEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('scheduleType'), 'exclude': lambda f: f is None }})
    r"""determine how the schedule data should be interpreted"""
    